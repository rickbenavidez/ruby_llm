---
http_interactions:
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-4.1-nano","messages":[{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"Hi"}],"stream":false}'
    headers:
      User-Agent:
      - Faraday v2.13.4
      Authorization:
      - Bearer <OPENAI_API_KEY>
      Content-Type:
      - application/json
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
  response:
    status:
      code: 429
      message: Too Many Requests
    headers:
      Date:
      - Sun, 14 Sep 2025 09:57:43 GMT
      Content-Type:
      - application/json; charset=utf-8
      Content-Length:
      - '427'
      Connection:
      - keep-alive
      Vary:
      - Origin
      X-Ratelimit-Limit-Requests:
      - '200'
      X-Ratelimit-Limit-Tokens:
      - '400000'
      X-Ratelimit-Remaining-Requests:
      - '199'
      X-Ratelimit-Remaining-Tokens:
      - '400000'
      X-Ratelimit-Reset-Requests:
      - 300ms
      X-Ratelimit-Reset-Tokens:
      - 0s
      X-Request-Id:
      - "<X_REQUEST_ID>"
      X-Envoy-Upstream-Service-Time:
      - '352'
      X-Openai-Proxy-Wasm:
      - v0.1
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - "<COOKIE>"
      - "<COOKIE>"
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Server:
      - cloudflare
      Cf-Ray:
      - "<CF_RAY>"
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: UTF-8
      string: |
        {
            "error": {
                "message": "Request too large for gpt-4.1-nano-long-context in organization org-eLwBCUaB2ePnSi6dlToWtHZK on tokens per min (TPM): Limit 400000, Requested 2500013. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.",
                "type": "tokens",
                "param": null,
                "code": "rate_limit_exceeded"
            }
        }
  recorded_at: Sun, 14 Sep 2025 09:57:43 GMT
recorded_with: VCR 6.3.1
